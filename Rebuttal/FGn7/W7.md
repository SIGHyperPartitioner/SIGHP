## Response
Q:  
Section 4.1.5 uses only two downstream tasks. Why not use more (e.g., BFS, DFS, etc.)?

A:  
We appreciate the reviewers' attention to the task selection in our study. We want to clarify that our choice of tasks was deliberate, focusing on selecting the most representative tasks to demonstrate the efficacy of our proposed approach. Specifically, we selected two categories of tasks: those representing high communication loads and those representing low communication loads.  
Certainly, we are committed to enhancing the comprehensiveness of our experimental evaluation. In response to the reviewers' feedback, we have included the label propagation algorithm. We believe that the inclusion of the label propagation algorithm enriches the diversity of our experimental setup and contributes to a more thorough understanding of hypergraph partitioning methodologies.  
In addition, based on the fact that algorithms such as HSSSP may have the need to run multiple times in practice, we expand the original HSSSP experiments to HSSSP-1 and HSSSP-10 to represent the total communication overhead and time overhead required to run a single HSSSP and 10 independent runs of HSSSP, respectively, and the results of the experiments show that the cumulative advantage of SIGHP will continue to grow as the number of runs increases.  


## Reference 
[1] Surana A, Chen C, Rajapakse I. Hypergraph similarity measures[J]. IEEE Transactions on Network Science and Engineering, 2022, 10(2): 658-674.  
[2] TUĞAL İ, Zeydin P. Centrality with Entropy in Hypergraphs Based on Similarity Measures[J]. Dicle Üniversitesi Mühendislik Fakültesi Mühendislik Dergisi, 2023, 14(3): 407-419.  

## Revision

we present the results of the newly added label propagation algorithm, and compare the performance of HSSSP after increasing the task execution times based on the reviewers' suggestions.
![](./pic/taskTable.png)

We update corresponding description of task in blue.
![](./pic/taskDescription.png)
